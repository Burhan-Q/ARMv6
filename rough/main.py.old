import gradio as gr
print(gr.__version__)
from discordwebhook import Discord
import requests
import time
import json
import chat
from rich import print
import control
import client
import copy 
import cv2 


import datetime
from log import log1
from elevenlabs import play , save
from elevenlabs.client import ElevenLabs
import uuid
import angle

global audipth
def send_(level, message):
    discord.post(content=f"[{level}]: {message}")


def act(prompt):
    #prompt=chat.gen_ai(prompt1)
   # print(f"======================= \n   IN {prompt1} \n OUT  {prompt}")
    if prompt[0] == "_":
        repp = paser(prompt)
        cmd = repp[1]
        respon = repp[0]
        print(f"=====================\n    {prompt} \n=======================     ")
       # logging.info(f'cmd: {cmd}')
       #old objs, origin,frame = vision.cam()
        objs, origin,frame = client.handshake()
        #if frame == None:
        #    _alert("Frame is a Nonetype")
       # logging.info(f'Vision.cam: {objs},{origin}')
        main1(cmd, objs, origin,frame)
    else:
        respon = prompt
        #logging.info(f'else: {prompt}')
    return respon
def frame_2(frame,data):
    height, width, channels = frame.shape


    new_frame = np.ones((height, width, channels), dtype=np.uint8) * 255


    text1 = str(data[0])
    text2 = str(data[1])
    text3 = str(data[2])

    font = cv2.FONT_HERSHEY_SIMPLEX
    font_scale = 1
    font_thickness = 2
    font_color = (0, 0, 0)  


  #  text1_position = (int((width - len(text1) * 20) / 2), int(height / 3))
   # text2_position = (int((width - len(text2) * 20) / 2), int(height / 2))
   # text3_position = (int((width - len(text3) * 20) / 2), int(2 * height / 3))

    cv2.putText(new_frame, text1, (14,150), font, font_scale, font_color, font_thickness, cv2.LINE_AA)
    cv2.putText(new_frame, text2, (14,250), font, font_scale, font_color, font_thickness, cv2.LINE_AA)
    cv2.putText(new_frame, text3, (14,300), font, font_scale, font_color, font_thickness, cv2.LINE_AA)
    return new_frame

def main1(cxv, objs, origin,frame):
    tokens = cxv.split('(')
    command = tokens[0].strip()
    args = tokens[1].rstrip(')').split(',')
    current_time = datetime.now()
    formatted_time = current_time.strftime("%Y-%m-%d %H:%M:%S")
    try:
        xxw = objs[str(args[0])]
    except Exception as e:
        print(f"OBJECT NOT FOUND   {e}")
    #cv2.imwrite(f'logs/obj3-{formatted_time}.jpg',frame)
    #b_a = angle.calculate_angle(13.5, 13.5, origin, 13.5, tuple(xxw)[0], atuple(xxw)[1])
    xxw=tuple(xxw[0])
   # print(xxw,origin,int(13.5),(0, 255, 0),4)
    frame1=copy.deepcopy(frame)
    frame2=copy.deepcopy(frame)
    ###BASE####
   # print(frame2, xxw, (int(origin),14), (0, 255, 0), 4)
    cv2.line(frame2,(13, 13),(int(origin), 13), (0, 255, 0), 4)
    
    cv2.line(frame2, xxw, (int(origin),14), (0, 255, 0), 4)

    b_a = angle.calculate_angle(int(origin),13,13,13,tuple(xxw)[0], tuple(xxw)[1])
    # just checking
  
    # print("========================")
    # print(angle.calculate_angle(13,13,int(origin),13, tuple(xxw)[0], tuple(xxw)[1]))
    # print(angle.calculate_angle(tuple(xxw)[0], tuple(xxw)[1],13,13,int(origin),13))
    # print(angle.calculate_angle(13,13,tuple(xxw)[0], tuple(xxw)[1],int(origin),13))
    # print(angle.calculate_angle(int(origin),13,13,13,tuple(xxw)[0], tuple(xxw)[1]))
    # print("========================")
    
    ###END###
    dist = angle.euclidean_distance_2d(xxw,(int(origin),14))
    data=(dist,b_a,objs)
    frame1=frame_2(frame=frame,data=data)
    imgstack=stack.stackImages(0.6,([frame,frame1,frame2]))
    dist = round(dist/10, 1)  # Round to 1 decimal place
   
    print("=================")
    print(f"BASE ANGLE {b_a}")
    print(f"distance {dist}")
    print(f"")
    print(f"")
    print("=================")
    cv2.imwrite(f'logs/obj-line {formatted_time}.jpg',imgstack)
    if command == '_move':
        pass
       # move(*args, xxw)
    elif command == '_pickup':
        control.pickup(base=b_a,x=dist,y=8) 
    elif command == '_drop':
       # drop(*args, xxw)
        pass 
    elif command == '_put':
      #  put(*args, xxw)
        pass
    else:
        print("Invalid syntax")

def paser(msg):
    original_string = msg
    parts = original_string.split('#')
    first_part = parts[0].strip()
    second_part = parts[1].strip()
    cmd = first_part
    repp = second_part
    return [repp, cmd]

# Example usage
def client2(file_path):
    upload_url = "https://4d34-34-91-176-161.ngrok-free.app/transcribe"  # Update with your server's URL

    # Open the audio file in binary mode
    with open(file_path, "rb") as file:
        # Create a dictionary containing the file
        files = {"file": file}
        
        # Record the start time
        start_time = time.time()
        
        # Send a POST request to upload the file
        response = requests.post(upload_url, files=files)
        
        # Record the end time
        end_time = time.time()

    # Calculate the elapsed time
    elapsed_time = end_time - start_time
    send_("INFO",f"res: {response} and completed in {elapsed_time} ")
    json_obj = response.json()

        # Extract the value associated with the key "text"
    text = json_obj["text"]
        
    return text
   
    
def generate(mic, text):
    send_("INFO", f"mic:{mic}, text:{text}")
    print(mic)
    
    if mic is not None:
        text= client2(mic)
        #print("GOT Audio")
        log1(f"RECIVED TEXT FROM MIC {text}")
        discord2.post(content=f" MIC {text}")
    else:
        #print("GOT TEXT")
        text=text["text"]
        log1(f"RECIVED TEXT FROM TEXT {text}")
        discord2.post(content=f" TEXT BOX {text}")

   # rep=chat.gen_ai(text)
    
    #!pip install elevenlabs

    objs, origin,frame = client.handshake()
    full_response = chat.gen_ai(prompt=f"you can see {objs}.  {text}") 
    print(f"======================= \n   IN you can see {objs}. {text} \n OUT  {full_response}")
    r_p=act(full_response)	
    discord2.post(content=f"{r_p}")
    log1(f"RESPONCES FOR LLM: {r_p}")

    client = ElevenLabs(
    api_ke# Defaults to ELEVEN_API_KEY
    )

    audio = client.generate(
    text="",
    voice="Josh",
    model="eleven_multilingual_v2"
    )
    audipth = uuid.uuid4()
    play(audio)
    TTSaudio = f"{audipth}.mp3"
    save(audio, "TTSaudio.mp3")

    return r_p ,"TTSaudio.mp3"   
    
    

def main():
    input_field = [gr.Microphone(type="filepath"),gr.MultimodalTextbox()] #gr.components.Textbox(label="Enter text")]
    #inputs=[gr.inputs.Audio(label="Upload audio"), gr.inputs.Textbox(label="Enter text")]
    output_text = [gr.components.Textbox(),gr.Audio("TTSaudio.mp3",autoplay=True,interactive=False)]
    text_reply = gr.Textbox(label="Text")
    voice_reply = gr.Audio('output.wav',autoplay=True)
    iface = gr.Interface(fn=generate, inputs=input_field, 
                         outputs=output_text, title="Text Generation App",
                         description="Enter text or upload an audio file and hit the 'Submit' button")
    
    iface.launch(debug=True)

if __name__ == '__main__':
    current_time = datetime.datetime.now().strftime("%I:%M:%S %p")
    log1(f"=============================== SERVER STARTED {current_time} ===============================")
   # print("started")

    main()

